{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e38bfc11",
   "metadata": {},
   "source": [
    "# Pink Floyd Lyrics Generator Using ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2be532",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81eff250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \"Moon in both [houses]...\"...Scorpio, [Arabian...\n",
       "1    Lucifer Sam, siam cat\\nAlways sitting by your ...\n",
       "2    There was a king who ruled the land\\nHis Majes...\n",
       "3    Alone in the clouds all blue\\nLying on an eide...\n",
       "4    TCH TCH\\nAHH (AHH)\\nTCH TCH\\nAHH AHH\\nDoi doi\\...\n",
       "5    Doctor, doctor!\\nI’m in bed (Doctor, doctor)\\n...\n",
       "6                                                  NaN\n",
       "7    I want to tell you a story\\nBout’ a little man...\n",
       "8    All movement is accomplished in six stages\\nAn...\n",
       "9    The black and green scarecrow as everyone know...\n",
       "Name: lyrics, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('pink_floyd_lyrics.csv')\n",
    "dataset = dataset['lyrics']\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c13ff7b",
   "metadata": {},
   "source": [
    "### Regular Expression to clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7872896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i] = re.sub(r'[ÁÀ]', 'A', str(dataset[i]))\n",
    "    dataset[i] = re.sub(r'[áà]', 'a', str(dataset[i]))\n",
    "    dataset[i] = re.sub(r'[ÉÈËЕ]', 'E', str(dataset[i]))\n",
    "    dataset[i] = re.sub(r'[éèëе]', 'e', str(dataset[i]))\n",
    "    dataset[i] = re.sub(r'[ÍÌ]', 'I', str(dataset[i]))\n",
    "    dataset[i] = re.sub(r'[íì]', 'i', str(dataset[i]))\n",
    "    dataset[i] = re.sub(r'[ÓÒŌ]', 'O', str(dataset[i]))\n",
    "    dataset[i] = re.sub(r'[óòō]', 'o', str(dataset[i]))\n",
    "    dataset[i] = re.sub(r'[ÚÙÜ]', 'U', str(dataset[i]))\n",
    "    dataset[i] = re.sub(r'[úùü]', 'u', str(dataset[i]))\n",
    "    dataset[i] = re.sub(r'[ćč]', 'c', str(dataset[i]))\n",
    "    dataset[i] = re.sub(r'[ĆČ]', 'c', str(dataset[i]))\n",
    "    dataset[i] = re.sub(r'[^a-zA-Z0-9ñÑ,.:;?[\\]()!\"\\'‘’“”…¡¿\\n ]', '', str(dataset[i]))\n",
    "dataset.to_csv('lyrics.txt', index=False, header=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1052a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"Moon in both [houses]...\"\"...Scorpio, [Arabian Skies], Libra...\"\"...Pluto was not discovered until 1930...\"\"\n",
      "Lime and limpid green, a second scene\n",
      "A fight between the blue you once knew\n",
      "Floating down, the sound resounds\n",
      "Around the icy waters underground\n",
      "Jupiter and Saturn, Oberon, Miranda and Tit\n"
     ]
    }
   ],
   "source": [
    "with open('lyrics.txt', 'r', encoding='utf-8') as file:\n",
    "    data = file.read()\n",
    "print(data[0:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b402f61e",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34c17ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(data)\n",
    "max_id = len(tokenizer.word_index)\n",
    "dataset_size = tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb032382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "[encoded] = np.array(tokenizer.texts_to_sequences([data])) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15672fd8",
   "metadata": {},
   "source": [
    "## Pre process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5afc389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c50b695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps + 1\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6c18c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73dcaa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(15)\n",
    "tf.random.set_seed(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1808cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd5c3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f82b21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100, 54) (32, 100)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.prefetch(1)\n",
    "for X_batch, Y_batch in dataset.take(1):\n",
    "    print(X_batch.shape, Y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2971a0c5",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f7a4e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2579/2579 [==============================] - 520s 199ms/step - loss: 1.9281\n",
      "Epoch 2/10\n",
      "2579/2579 [==============================] - 542s 209ms/step - loss: 1.5883\n",
      "Epoch 3/10\n",
      "2579/2579 [==============================] - 541s 209ms/step - loss: 1.4767\n",
      "Epoch 4/10\n",
      "2579/2579 [==============================] - 540s 209ms/step - loss: 1.4109\n",
      "Epoch 5/10\n",
      "2579/2579 [==============================] - 526s 203ms/step - loss: 1.3681\n",
      "Epoch 6/10\n",
      "2579/2579 [==============================] - 535s 207ms/step - loss: 1.3343\n",
      "Epoch 7/10\n",
      "2579/2579 [==============================] - 540s 209ms/step - loss: 1.3085\n",
      "Epoch 8/10\n",
      "2579/2579 [==============================] - 534s 206ms/step - loss: 1.2876\n",
      "Epoch 9/10\n",
      "2579/2579 [==============================] - 537s 207ms/step - loss: 1.2710\n",
      "Epoch 10/10\n",
      "2579/2579 [==============================] - 542s 209ms/step - loss: 1.2579\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = tf.keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                        dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                        dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ab17d8",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5cc917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c32891d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    Y_pred = model.predict(X_new, verbose=0)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(Y_pred) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fe11498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92131f45",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54bb2db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Money is gone that it's always been?\n",
      "could be the hoarts and haggles what have been and haggle\n",
      "for you?\n",
      "and did you know staining away?\"\n",
      "\"one sould, maggie, what have we gonna me trons\n",
      "in the window this sound of the night\n",
      "and if i can treat in the dream\n",
      "how can you ever wanted to be to rime\n",
      "\n",
      "fow you\n",
      "must he\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"Money is \", n_chars=300, temperature=0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39208cde",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca747478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el modelo\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2e07d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
